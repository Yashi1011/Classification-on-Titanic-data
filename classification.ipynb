{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interactive\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropdown widget function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropdown(a,des):\n",
    "    d = widgets.Dropdown(\n",
    "        options=a,\n",
    "        value=a[0],\n",
    "        description=des,\n",
    "        disabled=False,\n",
    "        continuous_update=True,\n",
    "        orientation='vertical',\n",
    "        readout=True\n",
    "    )\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slider widget function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slider(minimun, maximum, v, des):\n",
    "    d = widgets.IntSlider(\n",
    "        value=v,\n",
    "        min=minimun,\n",
    "        max=maximum,\n",
    "        step=1,\n",
    "        description=des,\n",
    "        disabled=False,\n",
    "        continuous_update=False,\n",
    "        readout=True\n",
    "    )\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X_train,X_test,y_train,y_test):\n",
    "    solver = dropdown(['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],'Solver')\n",
    "\n",
    "    multi_class = dropdown(['auto', 'ovr', 'multinomial'],'multi_class')\n",
    "\n",
    "    random_state = slider(0,100,0,'random_state')\n",
    "\n",
    "    def f(a,b,c):\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        r1 = LogisticRegression(solver=a, multi_class=b ,random_state=c)\n",
    "        r1.fit(X_train,y_train)\n",
    "\n",
    "        r1_pred = r1.predict(X_test)\n",
    "\n",
    "        c1 = confusion_matrix(y_test,r1_pred)\n",
    "        print(c1)\n",
    "        print(accuracy_score(y_test,r1_pred))\n",
    "\n",
    "    out = widgets.interactive_output(f, {'a': solver, 'b': multi_class, 'c': random_state})\n",
    "\n",
    "    display(solver, multi_class, random_state, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K - Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X_train,X_test,y_train,y_test):\n",
    "    n_neighbors = slider(1,100,5,'n_neighbours')\n",
    "    \n",
    "    weights = dropdown(['uniform', 'distance'],'Weights')\n",
    "    \n",
    "    algorithm = dropdown(['auto', 'ball_tree', 'kd_tree', 'brute'],'Algorithm')\n",
    "\n",
    "    def f(a,b,c):\n",
    "        from sklearn.neighbors import KNeighborsClassifier\n",
    "        r2 = KNeighborsClassifier(n_neighbors=a, weights=b, algorithm=c)\n",
    "        r2.fit(X_train,y_train)\n",
    "\n",
    "        r2_pred = r2.predict(X_test)\n",
    "\n",
    "        c2 = confusion_matrix(y_test,r2_pred)\n",
    "        print(c2)\n",
    "        print(accuracy_score(y_test,r2_pred))\n",
    "\n",
    "    out = widgets.interactive_output(f, {'a': n_neighbors, 'b': weights, 'c': algorithm})\n",
    "\n",
    "    display(n_neighbors, weights, algorithm, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(X_train,X_test,y_train,y_test):\n",
    "    kernel = dropdown(['linear', 'poly', 'rbf', 'sigmoid'],'kernel')\n",
    "    \n",
    "    degree = slider(0,10,3,'degree')\n",
    "    \n",
    "    gamma = dropdown(['scale', 'auto'], 'gamma')\n",
    "    \n",
    "    random_state = slider(0,100,0,'random_state')\n",
    "\n",
    "    def f(a,b,c,d):\n",
    "        from sklearn.svm import SVC\n",
    "        r3 = SVC(kernel=a, degree=b, gamma=c, random_state=d)\n",
    "        r3.fit(X_train, y_train)\n",
    "\n",
    "        r3_pred = r3.predict(X_test)\n",
    "\n",
    "        c3 = confusion_matrix(y_test,r3_pred)\n",
    "        print(c3)\n",
    "        print(accuracy_score(y_test,r3_pred))\n",
    "\n",
    "    out = widgets.interactive_output(f, {'a': kernel, 'b': degree, 'c': gamma, 'd': random_state})\n",
    "\n",
    "    display(kernel, degree, gamma, random_state, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(X_train,X_test,y_train,y_test):\n",
    "    \n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    r5 = GaussianNB()\n",
    "    r5.fit(X_train,y_train)\n",
    "    \n",
    "    r5_pred = r5.predict(X_test)\n",
    "    \n",
    "    c5 = confusion_matrix(y_test,r5_pred)\n",
    "    print(c5)\n",
    "    print(accuracy_score(y_test,r5_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X_train,X_test,y_train,y_test):\n",
    "    criterion = dropdown(['gini', 'entropy'],'criterion')\n",
    "    \n",
    "    splitter = dropdown(['best', 'random'], 'splitter')\n",
    "    \n",
    "    max_features = dropdown(['auto', 'sqrt', 'log2'], 'max_features')\n",
    "    \n",
    "    random_state = slider(0,100,0,'random_state')\n",
    "\n",
    "    def f(a,b,c,d):\n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        r6 = DecisionTreeClassifier(criterion=a, splitter=b,max_features=c,random_state=d)\n",
    "        r6.fit(X_train,y_train)\n",
    "\n",
    "        r6_pred = r6.predict(X_test)\n",
    "\n",
    "        c6 = confusion_matrix(y_test,r6_pred)\n",
    "        print(c6)\n",
    "        print(accuracy_score(y_test,r6_pred))\n",
    "\n",
    "    out = widgets.interactive_output(f, {'a': criterion, 'b': splitter, 'c': max_features, 'd': random_state})\n",
    "\n",
    "    display(criterion, splitter, max_features,random_state, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(X_train,X_test,y_train,y_test):\n",
    "    n_estimators = slider(1,100,10,'n_estimators')\n",
    "    \n",
    "    criterion = dropdown(['gini', 'entropy'],'criterion')\n",
    "    \n",
    "    max_features = dropdown(['auto', 'sqrt', 'log2'], 'max_features')\n",
    "    \n",
    "    random_state = slider(0,100,0,'random_state')\n",
    "    \n",
    "    def f(a,b,c,d):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        r7 = RandomForestClassifier(n_estimators=a,criterion=b, max_features=c,random_state=d)\n",
    "        r7.fit(X_train,y_train)\n",
    "\n",
    "        r7_pred = r7.predict(X_test)\n",
    "\n",
    "        c7 = confusion_matrix(y_test,r7_pred)\n",
    "        print(c7)\n",
    "        print(accuracy_score(y_test,r7_pred))\n",
    "        \n",
    "    out = widgets.interactive_output(f, {'a': n_estimators, 'b': criterion, 'c': max_features, 'd': random_state})\n",
    "\n",
    "    display(n_estimators, criterion, max_features,random_state, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('titanic.csv')\n",
    "X = dataset.iloc[:,[2,4,5,6,9]].values\n",
    "y=dataset.iloc[:,1].values\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "si = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X[:,2:] = si.fit_transform(X[:,2:])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[:,1] = le.fit_transform(X[:,1])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:,[2,4]] = sc.fit_transform(X_train[:,[2,4]])\n",
    "X_test[:,[2,4]]=sc.transform(X_test[:,[2,4]])\n",
    "\n",
    "model = widgets.RadioButtons(\n",
    "    options=['Logistic Regression', 'KNN', 'SVM', 'Naive Bayes', 'Decision Tree', 'Random Forest'],\n",
    "    value='Logistic Regression', # Defaults to 'Logistic regression'\n",
    "    description='Model',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def f(m):\n",
    "    print(m)\n",
    "    if (m=='Logistic Regression'):\n",
    "        logistic_regression(X_train,X_test,y_train,y_test)\n",
    "    elif (m=='KNN'):\n",
    "        knn(X_train,X_test,y_train,y_test)\n",
    "    elif (m=='SVM'):\n",
    "        svm(X_train,X_test,y_train,y_test)\n",
    "    elif (m=='Naive Bayes'):\n",
    "        naive_bayes(X_train,X_test,y_train,y_test)\n",
    "    elif (m=='Decision Tree'):\n",
    "        decision_tree(X_train,X_test,y_train,y_test)\n",
    "    else:\n",
    "        random_forest(X_train,X_test,y_train,y_test)\n",
    "    \n",
    "\n",
    "# Using interactive_output function to display output only once.\n",
    "o = widgets.interactive_output(f, {'m': model})\n",
    "\n",
    "display(model, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
